{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST: Digit Recognizer Getting Started Challenge\n",
    "\n",
    "*Author: Benjamin Sautermeister*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('inputs/train.csv')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('inputs/test.csv')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert image data to numpy array of type *float* and split the label out of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (train.iloc[:, 1:].values).astype(np.float32)\n",
    "y_train = (train.iloc[:, 0].values).astype(np.int32)\n",
    "x_test = test.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6, 9):\n",
    "    plt.subplot(330 + (i+1))\n",
    "    plt.imshow(x_train[i, :, :, 0], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(y_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x = x_train.mean().astype(np.float32)\n",
    "std_x = x_train.std().astype(np.float32)\n",
    "\n",
    "def standardize(x):\n",
    "    return (x - mean_x) / std_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "num_classes = y_train.shape[1]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = x_train\n",
    "label = y_train\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.10, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Lambda(standardize, input_shape=(28,28,1)),\n",
    "        tf.keras.layers.Conv2D(32,(3,3)),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.BatchNormalization(axis=1),\n",
    "        tf.keras.layers.Conv2D(32,(3,3)),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.BatchNormalization(axis=1),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Conv2D(64,(3,3)),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.BatchNormalization(axis=1),\n",
    "        tf.keras.layers.Conv2D(64,(3,3)),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.BatchNormalization(axis=1),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.005)\n",
    "    model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = gen.flow(x_train, y_train, batch_size=100)\n",
    "val_batches = gen.flow(x_val, y_val, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_acc', \n",
    "    patience=3, \n",
    "    verbose=1, \n",
    "    factor=0.5, \n",
    "    min_lr=0.00001)\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_acc',\n",
    "    min_delta=0.0001,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    baseline=None\n",
    ")\n",
    "\n",
    "checkpoint_model_selection_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='checkpoints/model_selection/ckp',\n",
    "    monitor='val_acc',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    period=1)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator=batches,\n",
    "    steps_per_epoch=batches.n,\n",
    "    epochs=25,\n",
    "    verbose=2,\n",
    "    validation_data=val_batches,\n",
    "    validation_steps=val_batches.n,\n",
    "    callbacks=[\n",
    "        checkpoint_model_selection_callback,\n",
    "        reduce_lr_callback,\n",
    "        early_stopping_callback\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_values(train_values, valid_values, y_label):\n",
    "    epochs = range(1, len(train_values) + 1)\n",
    "    plt.clf()\n",
    "    plt.plot(epochs, train_values, 'b')\n",
    "    if valid_values is not None:\n",
    "        plt.plot(epochs, valid_values, 'g')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(y_label)\n",
    "    plt.show()\n",
    "    \n",
    "history_dict = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "plot_values(loss_values, val_loss_values, 'Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "plot_values(acc_values, val_acc_values, 'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option A: Retrain on full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "checkpoint_train_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='checkpoints/train/ckp',\n",
    "    monitor='acc',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    period=1)\n",
    "\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='acc', \n",
    "    patience=2, \n",
    "    verbose=1, \n",
    "    factor=0.5, \n",
    "    min_lr=0.00001)\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='acc',\n",
    "    min_delta=0.0001,\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    baseline=None\n",
    ")\n",
    "\n",
    "batches = gen.flow(inputs, label, batch_size=100)\n",
    "history = model.fit_generator(\n",
    "    generator=batches,\n",
    "    steps_per_epoch=batches.n,\n",
    "    epochs=10,\n",
    "    verbose=2,\n",
    "    callbacks=[\n",
    "        checkpoint_train_callback,\n",
    "        reduce_lr_callback,\n",
    "        early_stopping_callback\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option B: Load best checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "latest = tf.train.latest_checkpoint('checkpoints/train')\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "plot_values(loss_values, None, 'Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_values = history_dict['acc']\n",
    "plot_values(acc_values, None, 'Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(x_test, verbose=0)\n",
    "\n",
    "submissions=pd.DataFrame({\n",
    "    \"ImageId\": list(range(1,len(predictions)+1)),\n",
    "    \"Label\": predictions\n",
    "})\n",
    "submissions.to_csv(\"submission.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3 ML-CH-GPU",
   "language": "python",
   "name": "venv-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
