{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pump it Up: Data Mining the Water Table\n",
    "\n",
    "### Can you predict which water pumps are faulty?\n",
    "Using data from Taarifa and the Tanzanian Ministry of Water, can you predict which pumps are functional, which need some repairs, and which don't work at all? This is an intermediate-level practice competition. Predict one of these three classes based on a number of variables about what kind of pump is operating, when it was installed, and how it is managed. A smart understanding of which waterpoints will fail can improve maintenance operations and ensure that clean, potable water is available to communities across Tanzania.\n",
    "\n",
    "Competition:\n",
    "https://www.drivendata.org/competitions/7/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data and load with pandas\n",
    "TRAIN_DATA_URL = 'https://s3.amazonaws.com/drivendata/data/7/public/4910797b-ee55-40a7-8668-10efd5c1b960.csv'\n",
    "TRAIN_LABELS_URL = 'https://s3.amazonaws.com/drivendata/data/7/public/0bf8bc6e-30d0-4c50-956a-603fc693d966.csv'\n",
    "TEST_DATA_URL = 'https://s3.amazonaws.com/drivendata/data/7/public/702ddfc5-68cd-4d1d-a0de-f5f566f76d91.csv'\n",
    "\n",
    "train_values = pd.read_csv(TRAIN_DATA_URL,\n",
    "                           index_col='id')\n",
    "train_targets = pd.read_csv(TRAIN_LABELS_URL,\n",
    "                            index_col='id')\n",
    "test_values = pd.read_csv(TEST_DATA_URL,\n",
    "                          index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge training values and labels as a copy\n",
    "train = pd.merge(train_values, train_targets, left_index=True, right_index=True).copy()\n",
    "test = test_values.copy()\n",
    "\n",
    "def status_group_mapper(status_group: str):\n",
    "    if status_group == 'functional':\n",
    "        return 2\n",
    "    elif status_group == 'non functional':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# map status_group label to numeric class (0: non-func, 1: repair, 2: func)\n",
    "train['status_group'] = train['status_group'].apply(status_group_mapper)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all object-columns to lower-case\n",
    "def dataset_string_to_lowercase(df: pd.DataFrame):\n",
    "    for cname in df.columns:\n",
    "        if df[cname].dtype == object:\n",
    "            df[cname] = df[cname].str.lower()\n",
    "\n",
    "dataset_string_to_lowercase(train)\n",
    "dataset_string_to_lowercase(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the dataset\n",
    "\n",
    "- amount_tsh - Total static head (amount water available to waterpoint)\n",
    "- date_recorded - The date the row was entered\n",
    "- funder - Who funded the well\n",
    "- gps_height - Altitude of the well\n",
    "- installer - Organization that installed the well\n",
    "- longitude - GPS coordinate\n",
    "- latitude - GPS coordinate\n",
    "- wpt_name - Name of the waterpoint if there is one\n",
    "- num_private -\n",
    "- basin - Geographic water basin\n",
    "- subvillage - Geographic location\n",
    "- region - Geographic location\n",
    "- region_code - Geographic location (coded)\n",
    "- district_code - Geographic location (coded)\n",
    "- lga - Geographic location\n",
    "- ward - Geographic location\n",
    "- population - Population around the well\n",
    "- public_meeting - True/False\n",
    "- recorded_by - Group entering this row of data\n",
    "- scheme_management - Who operates the waterpoint\n",
    "- scheme_name - Who operates the waterpoint\n",
    "- permit - If the waterpoint is permitted\n",
    "- construction_year - Year the waterpoint was constructed\n",
    "- extraction_type - The kind of extraction the waterpoint uses\n",
    "- extraction_type_group - The kind of extraction the waterpoint uses\n",
    "- extraction_type_class - The kind of extraction the waterpoint uses\n",
    "- management - How the waterpoint is managed\n",
    "- management_group - How the waterpoint is managed\n",
    "- payment - What the water costs\n",
    "- payment_type - What the water costs\n",
    "- water_quality - The quality of the water\n",
    "- quality_group - The quality of the water\n",
    "- quantity - The quantity of water\n",
    "- quantity_group - The quantity of water\n",
    "- source - The source of the water\n",
    "- source_type - The source of the water\n",
    "- source_class - The source of the water\n",
    "- waterpoint_type - The kind of waterpoint\n",
    "- waterpoint_type_group - The kind of waterpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_plot(cols):\n",
    "    sns.set(style='whitegrid',context='notebook')\n",
    "    sns.pairplot(train[cols],size=2.5)\n",
    "    plt.show()\n",
    "    \n",
    "matrix_plot(['amount_tsh','num_private','population','status_group'])\n",
    "matrix_plot(['gps_height','latitude', 'longitude','status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_redundant(col1, col2):\n",
    "    result = np.where(train[col1] != train[col2])[0]\n",
    "    print('{} != {}: {}/{}'.format(col1, col2, result.size, len(train)))\n",
    "\n",
    "# check redundancies\n",
    "check_redundant('quantity', 'quantity_group')\n",
    "check_redundant('waterpoint_type', 'waterpoint_type_group')\n",
    "check_redundant('water_quality', 'quality_group')\n",
    "check_redundant('management', 'management_group')\n",
    "check_redundant('payment', 'payment_type') # different naming, but is identical\n",
    "check_redundant('source', 'source_type')\n",
    "check_redundant('source', 'source_class')\n",
    "check_redundant('extraction_type', 'extraction_type_group')\n",
    "check_redundant('extraction_type', 'extraction_type_class')\n",
    "check_redundant('funder', 'installer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### quantity, quantity_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove or merge redundant columns\n",
    "train = train.drop(columns=['quantity_group'])\n",
    "test = test.drop(columns=['quantity_group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['population']>0, 'population'].plot(kind='hist', title='TRAIN', bins=50)\n",
    "plt.show()\n",
    "test.loc[test['population']>0, 'population'].plot(kind='hist', title='TEST', bins=50)\n",
    "plt.show()\n",
    "\n",
    "# TODO: binning ? (p<10, 10<=p<100, 100<=p<500, 500<=p<1000, 1000<=p, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### funder, installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 0 (zero) / NAs in columns other/unknown\n",
    "train = train.drop(columns=['funder'])\n",
    "train = train.replace({'installer':'0'}, 'unknown')\n",
    "train = train.replace({'installer': np.nan}, 'unknown')\n",
    "\n",
    "test = test.drop(columns=['funder'])\n",
    "test = test.replace({'installer':'0'}, 'unknown')\n",
    "test = test.replace({'installer': np.nan}, 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_mapper(value: str, contains: str, label: str):\n",
    "    if contains in value:\n",
    "        return label\n",
    "    return value\n",
    "\n",
    "train['installer'] = train['installer'].apply(lambda v : replace_mapper(v, 'gov', 'government'))\n",
    "train['installer'] = train['installer'].apply(lambda v : replace_mapper(v, 'comm', 'community'))\n",
    "train['installer'] = train['installer'].apply(lambda v : replace_mapper(v, 'danid', 'danida'))\n",
    "\n",
    "test['installer'] = test['installer'].apply(lambda v : replace_mapper(v, 'gov', 'government'))\n",
    "test['installer'] = test['installer'].apply(lambda v : replace_mapper(v, 'comm', 'community'))\n",
    "test['installer'] = test['installer'].apply(lambda v : replace_mapper(v, 'danid', 'danida'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installer = train['installer'].value_counts()\n",
    "installer_few = train['installer'].isin(installer.index[installer < 100])\n",
    "train.loc[installer_few, 'installer'] = 'other'\n",
    "train['installer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installer_values = train['installer'].unique()\n",
    "\n",
    "test['installer'] = test['installer'].apply(lambda v: 'other' if v not in installer_values else v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### waterpoint, waterpoint_type_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['waterpoint_type'].value_counts(dropna=False))\n",
    "print(train['waterpoint_type_group'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dam (only 7 instances) to others, and drop waterpoint_type_group\n",
    "train = train.replace({'waterpoint_type':'dam'}, 'other')\n",
    "train = train.drop(columns=['waterpoint_type_group'])\n",
    "\n",
    "test = test.replace({'waterpoint_type':'dam'}, 'other')\n",
    "test = test.drop(columns=['waterpoint_type_group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### construction_year, date_recorded, well_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim the record date to the year\n",
    "train['date_recorded'] = train['date_recorded'].apply(lambda v : float(v[:4]))\n",
    "test['date_recorded'] = test['date_recorded'].apply(lambda v : float(v[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill construction_year==0 with the min value (I expect that the year is unknown because it's a while ago)\n",
    "train = train.replace({'construction_year':0}, np.nan)\n",
    "test = test.replace({'construction_year':0}, np.nan)\n",
    "min_construction_year = int(train['construction_year'].min())\n",
    "train = train.replace({'construction_year':np.nan}, min_construction_year)\n",
    "test = test.replace({'construction_year':np.nan}, min_construction_year)\n",
    "\n",
    "# create a new column 'well_age'\n",
    "train['well_age'] = train['date_recorded'] - train['construction_year']\n",
    "test['well_age'] = test['date_recorded'] - test['construction_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['well_age'] < 0, ['date_recorded', 'construction_year', 'well_age', 'status_group']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date_recorded < construction_year seams to be an error. Since date_recorded is always 2004, this looks like an systematic error. Could be a typo and 2014 instead of 2014.\n",
    "\n",
    "Here, we simply make a value zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['well_age'] < 0, 'well_age'] = 0\n",
    "test.loc[test['well_age'] < 0, 'well_age'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extraction_type, extraction_type_group, extraction_type_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['extraction_type'].value_counts())\n",
    "print(train['extraction_type_group'].value_counts())\n",
    "print(train['extraction_type_class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only keep extraction_type_class, since all are quite similar and this one has the most understandable groups\n",
    "train = train.drop(columns=['extraction_type', 'extraction_type_class'])\n",
    "test = test.drop(columns=['extraction_type', 'extraction_type_class'])\n",
    "\n",
    "train = train.replace({'extraction_type_group':'india mark ii'}, 'india mark')\n",
    "train = train.replace({'extraction_type_group':'india mark iii'}, 'india mark')\n",
    "test = test.replace({'extraction_type_group':'india mark ii'}, 'india mark')\n",
    "test = test.replace({'extraction_type_group':'india mark iii'}, 'india mark')\n",
    "\n",
    "train['extraction_type_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = train[train['extraction_type_group'] == 'wind-powered']\n",
    "cross_table = pd.crosstab(index=selected['extraction_type_group'], columns=train['status_group'])\n",
    "cross_table\n",
    "cross_table.plot(kind='bar', stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### latitude, longitude, gps_height\n",
    "- there are many zero (0 or -2e-8) which is not withing Tanzania (lat: (-11, -1), lng: (30, 40))\n",
    "- height extremes in Tanzania are 0 to 5,895m. Minus values might be underground. Many empty 0 values.\n",
    "- use basin to estimate the apprx. location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure all unknown values are zero (0):\n",
    "train = train.replace({'latitude':-2.000000e-08}, 0)\n",
    "test = test.replace({'latitude':-2.000000e-08}, 0)\n",
    "\n",
    "# bounds of min/max latitude/longitude/height for Tanzania using basin\n",
    "train_bound = train[(train['latitude']!=0)&(train['longitude']!=0)&(train['gps_height']!=0)]\n",
    "train_median_geo = train_bound.groupby(['basin',])['latitude','longitude','gps_height'].median()\n",
    "train_median_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['gps_height']==0, 'gps_height'] = train['basin'].apply(lambda x : train_median_geo.at[x,'gps_height'])\n",
    "train.loc[train['longitude']==0, 'longitude'] = train['basin'].apply(lambda x : train_median_geo.at[x,'longitude'])\n",
    "train.loc[train['latitude']==0, 'latitude'] = train['basin'].apply(lambda x : train_median_geo.at[x,'latitude'])\n",
    "\n",
    "test.loc[test['gps_height']==0, 'gps_height'] = test['basin'].apply(lambda x : train_median_geo.at[x,'gps_height'])\n",
    "test.loc[test['longitude']==0, 'longitude'] = test['basin'].apply(lambda x : train_median_geo.at[x,'longitude'])\n",
    "test.loc[test['latitude']==0, 'latitude'] = test['basin'].apply(lambda x : train_median_geo.at[x,'latitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['scheme_management', 'scheme_name', 'management', 'management_group']].head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train['scheme_management'].value_counts()) # almost same as management, but with NaN values\n",
    "# print(train['scheme_name'].value_counts()) # 2576 different values!\n",
    "print(train['management'].value_counts())\n",
    "print(train['management_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace({'management':'unknown'}, 'other')\n",
    "train = train.replace({'management': 'other - school'}, 'other')\n",
    "train = train.replace({'management': 'trust'}, 'other')\n",
    "train = train.replace({'management_group':'unknown'}, 'other')\n",
    "\n",
    "test = test.replace({'management':'unknown'}, 'other')\n",
    "test = test.replace({'management': 'other - school'}, 'other')\n",
    "test = test.replace({'management': 'trust'}, 'other')\n",
    "test = test.replace({'management_group':'unknown'}, 'other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### region / district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['region', 'region_code', 'district_code']].head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "region, region_code and district seem to be very similar. We will use region and binarize it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['basin'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['source'].value_counts())\n",
    "print(train['source_type'].value_counts())\n",
    "print(train['source_class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace({'source':'unknown'}, 'other')\n",
    "test = test.replace({'source':'unknown'}, 'other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['payment'].value_counts())\n",
    "print(train['payment_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize cleaned data\n",
    "\n",
    "Some more visualization after the data has been cleaned up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosstab_diagram(data: pd.DataFrame, index_col: str, figsize=None):\n",
    "    cross_table = pd.crosstab(index=data[index_col], columns=data['status_group'])\n",
    "    cross_table.plot(kind='bar', stacked=True, figsize=figsize)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_diagram(train, 'quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_diagram(train, 'waterpoint_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_diagram(train, 'extraction_type_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_diagram(train, 'region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_diagram(train, 'management')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_diagram(train, 'management_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_diagram(train, 'source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_diagram(train, 'source_class') # does not seam to be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_diagram(train, 'payment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_diagram(train, 'installer', figsize=(16,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_diagram(train, 'basin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_diagram(train, 'well_age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_diagram(train, 'construction_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes that we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['gps_height', 'latitude', 'longitude', 'well_age', 'construction_year', 'population']\n",
    "ordered_cat_cols = []\n",
    "unordered_cat_cols = ['quantity', 'waterpoint_type', 'extraction_type_group', 'region',\\\n",
    "                      'management', 'source',\\\n",
    "                      'payment', 'installer', 'basin'] # source_class, management_group\n",
    "all_cols = numeric_cols + ordered_cat_cols + unordered_cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[all_cols].to_csv('data/train_clean.csv')\n",
    "test[all_cols].to_csv('data/test_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical attributes\n",
    "- LabelEncoder (ordered)\n",
    "- LabelBinarizer (unordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categories(column: pd.core.series.Series):\n",
    "    encoder = LabelBinarizer()\n",
    "    return encoder.fit_transform(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column_name in unordered_cat_cols:\n",
    "    # train[column_name] = encode_categories(train[column_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_categories(train['quantity'])\n",
    "# train['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training = pd.get_dummies(train[all_cols], columns=unordered_cat_cols)\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.get_dummies(test[all_cols], columns=unordered_cat_cols)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "\n",
    "dfTest[['A','B','C']] = scale.fit_transform(dfTest[['A','B','C']].as_matrix()) ??? # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "normalized_df=(df-df.mean())/df.std()\n",
    "\n",
    "training = pd.ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = training.as_matrix()\n",
    "train_labels = train['status_group'].as_matrix()\n",
    "test_data = testing.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
    "            criterion='gini', max_depth=16, max_features='log2',\n",
    "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
    "            oob_score=False, random_state=None, verbose=0, warm_start=False,\n",
    "            random_state=42)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(max_depth=10, n_estimators=500, learning_rate=0.1, reg_alpha=0, reg_lambda=1.0,\n",
    "                          random_state=42)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.2, random_state=0)\n",
    "#X_train, y_train = (train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(X_test)\n",
    "plt.hist(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train)\n",
    "accuracy_score(y_true=y_train, y_pred=pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confmat = confusion_matrix(y_true=y_train, y_pred=pred_train)\n",
    "confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = cross_val_score(model, train_data, train_labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scores: {}'.format(model_scores))\n",
    "print('Mean: {}'.format(model_scores.mean()))\n",
    "print('Std: {}'.format(model_scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_data)\n",
    "plt.hist(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(predictions, test):\n",
    "    data = {'id': test.index, 'status_group': predictions}\n",
    "\n",
    "    submit = pd.DataFrame(data=data)\n",
    "\n",
    "    vals_to_replace = {0:'non functional',\n",
    "                       1:'functional needs repair',\n",
    "                       2:'functional'}\n",
    "\n",
    "    submit['status_group'] = submit['status_group'].replace(vals_to_replace)        \n",
    "\n",
    "    submit.to_csv('pump_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(prediction, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
